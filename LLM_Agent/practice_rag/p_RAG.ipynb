{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ecde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "논문 처리: 100%|██████████| 3/3 [01:12<00:00, 24.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"메타버스_가상_콘서트_소비자.pdf\": {\n",
      "    \"field\": [],\n",
      "    \"topics\": [],\n",
      "    \"methodologies\": []\n",
      "  },\n",
      "  \"가상 아이돌 이용자 연구.pdf\": {\n",
      "    \"field\": [],\n",
      "    \"topics\": [],\n",
      "    \"methodologies\": []\n",
      "  },\n",
      "  \"BTS와 이세계아이돌 유튜브 콘텐츠 댓글 비교 형용사 사용 패턴과 텍스트마이닝을 통한 정서.pdf\": {\n",
      "    \"field\": [],\n",
      "    \"topics\": [],\n",
      "    \"methodologies\": []\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 2. 논문 파일 경로 리스트 (예: [\"paper1.pdf\", \"paper2.pdf\", ...])\n",
    "pdf_paths = [\n",
    "    \"./메타버스_가상_콘서트_소비자.pdf\",\n",
    "    \"./가상 아이돌 이용자 연구.pdf\",\n",
    "    \"./BTS와 이세계아이돌 유튜브 콘텐츠 댓글 비교 형용사 사용 패턴과 텍스트마이닝을 통한 정서.pdf\",\n",
    "]\n",
    "\n",
    "# 3. PDF → 텍스트 분할기\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# 4. LLM 및 프롬프트 설정\n",
    "llm = OpenAI(model='gpt-4.1-nano')\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"\"\"\n",
    "첨부한 논문에서 다음 세 가지 정보를 키워드(간단명) 형태로 뽑아줘:\n",
    "1. 분야 (field)\n",
    "2. 주제 (topics)\n",
    "3. 사용된 연구방법론 (methodologies)\n",
    "\n",
    "결과를 JSON으로만 반환해줘. \n",
    "예시:\n",
    "{{\n",
    "  \"field\": [\"Computer Vision\", \"...\"],\n",
    "  \"topics\": [\"object detection\", \"...\"],\n",
    "  \"methodologies\": [\"CNN\", \"transfer learning\", \"...\"]\n",
    "}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# 5. 전체 논문 순회하며 처리\n",
    "results = {}\n",
    "for path in tqdm(pdf_paths, desc=\"논문 처리\"):\n",
    "    # (1) 로드\n",
    "    loader = PyMuPDFLoader(path)\n",
    "    docs = loader.load()\n",
    "    # (2) 텍스트 청크로 분할\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    # (3) 각 청크에 LLM 요청, 결과 수집\n",
    "    aggregated = {\"field\": set(), \"topics\": set(), \"methodologies\": set()}\n",
    "    for chunk in chunks:\n",
    "        resp = chain.run(text=chunk.page_content)\n",
    "        try:\n",
    "            data = json.loads(resp)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "        for key in aggregated:\n",
    "            for item in data.get(key, []):\n",
    "                aggregated[key].add(item.strip())\n",
    "    # (4) set → list 변환 후 저장\n",
    "    results[os.path.basename(path)] = {\n",
    "        \"field\": list(aggregated[\"field\"]),\n",
    "        \"topics\": list(aggregated[\"topics\"]),\n",
    "        \"methodologies\": list(aggregated[\"methodologies\"])\n",
    "    }\n",
    "\n",
    "# 6. 최종 JSON 출력\n",
    "print(json.dumps(results, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac37ee4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m sample = docs[:\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# 첫 청크만\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m info = \u001b[43mextract_chain\u001b[49m.run_and_parse(sample)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(info.dict())\n",
      "\u001b[31mNameError\u001b[39m: name 'extract_chain' is not defined"
     ]
    }
   ],
   "source": [
    "sample = docs[:1]  # 첫 청크만\n",
    "info = extract_chain.run_and_parse(sample)\n",
    "print(info.dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
