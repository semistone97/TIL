{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3a7886",
   "metadata": {},
   "source": [
    "# Langchain Intro\n",
    "\n",
    "`01_langchin_intro.ipynb`\n",
    "\n",
    "- LLM powered 어플리케이션 제작을 위한 프레임워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4997f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# 원래 이걸 해야 llm 활용이 가능(API키를 참조해야하기 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe3acc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello there! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 11, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAoKTxI6RkzMHhqtOS9ArqqRKUKJU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--afa663e5-2309-47e5-a1f6-23183cc0bbc7-0', usage_metadata={'input_tokens': 11, 'output_tokens': 10, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98983606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'나는 한국 사람이에요.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 외국어로 들어온 메시지를 한국어로 번역하는 AI를 만들고 싶다면?\n",
    "# llm.invoke('한국어로 번역해줘: invoke')\n",
    "# llm.invoke('Great') # 기억을 못 함\n",
    "msg = input('외국어를 넣으세요')\n",
    "res = llm.invoke(f'한국어로 번역해줘: {msg}')\n",
    "\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e6ec48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='満腹です。(만부쿠 데스)', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 94, 'total_tokens': 110, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqIB7VAKLvuux8aCoj5eocHgZB03', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--220a180f-4b15-47fb-a2b5-5552007b7615-0', usage_metadata={'input_tokens': 94, 'output_tokens': 16, 'total_tokens': 110, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    # 채팅 세션의 전체적인 안내 사항\n",
    "    SystemMessage(content='너는 매우 쉽게 설명하는 전문가야. 이제부터 모든 영어를 이탈리아어로 번역해.'),\n",
    "    {'role': 'system', 'content': '한국어를 일본어로 번역해줘(영어발음도 같이 써줘)'},\n",
    "    {'role': 'user', 'content': '배부르다.'}\n",
    "    # Use one of 'human', 'user', 'ai', 'assistant', 'function', 'tool', 'system', or 'developer'.\n",
    "    # HumanMessage(content='점심을 먹자. 뭘 먹는 게 좋을까?')\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0a84ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|お|な|か|が|い|っ|ぱ|い|です|。(|on|aka|-g|a| |ipp|ai| des|u|)||"
     ]
    }
   ],
   "source": [
    "for token in llm.stream(messages):\n",
    "    print(token.content, end='|')\n",
    "\n",
    "# 참고로 llm의 class는 runable에서 왔음.(중요!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11715082",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "- 고정된 문자열과 변수를 조합하여 프롬프트를 만드는 방법\n",
    "- 생긴 건 f-string이랑 흡사\n",
    "\n",
    "## Chain\n",
    "- Langchain의 각 구성요소를 묶어서(chaining)하여 한 번에 실행(invoke)할 수 있도록 하는 기능\n",
    "- `a | b | c` 형태. Python 아니고, Langchain 문법(LCEL, LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b7d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='やめてくれ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 20, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqdX4paW2U6WN8FMzqZcWAPpB5Bx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--2a549dcc-c919-4c91-8022-1c2f228a79c6-0', usage_metadata={'input_tokens': 20, 'output_tokens': 5, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'Translate Korean to {lang}'},\n",
    "    {'role': 'user', 'content': '{text}'} # 얘는 f-string이 아님. langchain에서 쓰는 특수문법임.\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "prompt = prompt_template.invoke({'lang': 'japanese', 'text': input()})\n",
    "\n",
    "prompt.to_messages()\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c181900b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am Korean.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 21, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqqJXqgiX3NFftVGFos0yUdLraIR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--cd11965d-17c8-4dee-9f21-b89467b5ac37-0', usage_metadata={'input_tokens': 21, 'output_tokens': 4, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({'lang': 'english', 'text': 'wo shi hanguoren'})\n",
    "\n",
    "llm.invoke(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa5a2e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我想赚钱~'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke({'lang': '중국어', 'text': 'I want to earn money~'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed99b25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You shouldn't waste your time dreaming of becoming a pro gamer. It's not a realistic career path. \n",
      "너는 프로게이머가 되는 꿈을 꾸는 시간을 낭비해서는 안 돼. 그것은 현실적인 직업 경로가 아니야.\n"
     ]
    }
   ],
   "source": [
    "# 단발성 명령 수행 Prompt Template\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# 각종 정재계 소식을 꿰고 있으며, 관련 정보를 간결하면서도 명확하게 전달하죠.\n",
    "\n",
    "template = \"\"\"\n",
    "당신은 재야의 영어 초고수입니다. \n",
    "상황에 맞게 [FORMAT]에 영어 회화를 작성해주세요.\n",
    "\n",
    "상황: {question}\n",
    "\n",
    "FORMAT:\n",
    "- 영어 회화 문장\n",
    "- 한글 번역 문장\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "res = chain.invoke({'question': '프로게이머를 꿈꾸는 중학생에게 꿈을 짓밟는 이야기를 해줄 때'})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd38c122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^-^ Our^ sales^ analysis^ for^ the^ first^ half^ of^ ^202^5^ shows^ a^ significant^ increase^ compared^ to^ last^ year^.\n",
      "^-^ ^202^5^년^ 상^반^기^ 매^출^ 분^석^ 결과^,^ 작^년^ 대^비^ 상^당^한^ 증^가^를^ 보^여^줍^니다^.^^"
     ]
    }
   ],
   "source": [
    "# Chain is Runnable object, so you can use invoke, stream, batch method\n",
    "for token in chain.stream({'question': '이번 2025년 전반기 매출 분석'}):\n",
    "    print(token, end='^', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3a72ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Langchain is an open-source framework designed to facilitate the development of applications that leverage large language models (LLMs), enabling developers to easily build, manage, and deploy AI-powered tools. It provides modular components for tasks such as prompt management, data extraction, and integration with various data sources, streamlining the process of creating intelligent systems. By offering tools for chaining together multiple language model interactions, Langchain enables the creation of complex, multi-step workflows for tasks like question answering, chatbots, and data analysis.',\n",
       " 'Langsmith is an emerging platform designed to facilitate the development and deployment of advanced language models and conversational AI applications. It offers tools for model training, fine-tuning, and integration, making it accessible for developers to create customized AI solutions. By streamlining the AI development process, Langsmith aims to enhance productivity and innovation in natural language processing projects.',\n",
       " 'LangGraph is a neural network architecture designed to model and generate structured language representations by integrating linguistic graph structures with language models. It leverages graph-based methods to capture relationships between words, phrases, and syntactic or semantic components, enhancing language understanding and generation tasks. By combining graph neural networks with traditional language models, LangGraph aims to improve performance on complex NLP tasks such as parsing, translation, and reasoning.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch\n",
    "\n",
    "prompt = prompt_template.from_template('Explain about {topic} in 3 sentences.')\n",
    "llm  = ChatOpenAI(model='gpt-4.1-nano')\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "chain.batch([\n",
    "    {'topic': 'Langchain'},\n",
    "    {'topic': 'Langsmith'},\n",
    "    {'topic': 'Langgraph'},\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
