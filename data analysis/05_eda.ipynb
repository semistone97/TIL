{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f7f9a8",
   "metadata": {},
   "source": [
    "# 왜 안 도ㅑㅐ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "plt.rcParams['font.family'] = 'GmarketSans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "boston = pd.read_csv('./boston-housing.csv', header=None, sep=r'\\s+')\n",
    "boston.columns = ['CRIM', 'Z'\n",
    "'N', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'PRICE']\n",
    "display(boston.head())  # print 말고 dataframe 제대로 보고싶으면 사용하는 법.\n",
    "# print(boston.head())  # 얘는 못생김.\n",
    "\n",
    "# 변수 설명 딕셔너리\n",
    "feature_descriptions = {\n",
    "    'CRIM': '지역별 1인당 범죄율',\n",
    "    'ZN': '25,000 sq.ft. 이상 주거지역 비율',\n",
    "    'INDUS': '비소매업 지역 비율', \n",
    "    'CHAS': '찰스강 인접 여부 (1: 인접, 0: 비인접)',\n",
    "    'NOX': '일산화질소 농도 (ppm)',\n",
    "    'RM': '주택당 평균 방 개수',\n",
    "    'AGE': '1940년 이전 건축 주택 비율',\n",
    "    'DIS': '보스턴 고용센터까지 가중거리',\n",
    "    'RAD': '방사형 고속도로 접근성 지수',\n",
    "    'TAX': '재산세율',\n",
    "    'PTRATIO': '학생-교사 비율',\n",
    "    'B': '흑인 거주 비율 관련 지수',\n",
    "    'LSTAT': '하위계층 비율',\n",
    "    'PRICE': '주택 중간값 (단위: $1000)'\n",
    "}\n",
    "\n",
    "for var, desc in feature_descriptions.items():\n",
    "    print(f\"  {var}: {desc}\")\n",
    "\n",
    "print(f\"\\n기본 정보:\")\n",
    "print(boston.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a1cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi.background import P\n",
    "\n",
    "\n",
    "def get_data_profile(df: pd.DataFrame, target_col=None):\n",
    "    \"\"\"종합적인 데이터 프로파일링 함수\"\"\"\n",
    "    print('=' * 50)\n",
    "    print('종합 데이터 품질 리포트')\n",
    "    print('=' * 50)\n",
    "\n",
    "    # 1. 기본 통계\n",
    "    print(f'\\n1. 기본정보')\n",
    "    print(f'- 데이터 크기: {df.shape[0]}행 x {df.shape[1]}열')\n",
    "    print(f'- 메모리 사용량: {df.memory_usage(deep=True).sum()/1024**2:.2f}mb')\n",
    "    print(f'- 수치형 변수: {len(df.select_dtypes(include=['number']).columns)}개')\n",
    "    print(f'- 범주형 변수: {len(df.select_dtypes(include=['object']).columns)}개')\n",
    "\n",
    "    # 2. 결측값 분석\n",
    "    print(f'\\n2. 결측값 분석')\n",
    "    missing_info = df.isnull().sum()\n",
    "    m_pct = (missing_info / len(df)) * 100\n",
    "    if missing_info.sum() == 0:\n",
    "        print('결측값 없음. 완전')\n",
    "    else:\n",
    "        missing_sum = pd.DataFrame({\n",
    "            '결측수': missing_info,\n",
    "            '결측율(%)': m_pct,\n",
    "        }).round(2)\n",
    "        missing_sum = missing_sum[missing_sum['결측수'] > 0]\n",
    "        display(missing_sum)\n",
    "\n",
    "    # 3. 데이터 타입별 분석\n",
    "    print(f'\\n3. 수치형 변수 품질 분석')\n",
    "    num_cols = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "    quality_report = []\n",
    "    for col in num_cols:\n",
    "        col_data = df[col].dropna()\n",
    "        # 기본 통계\n",
    "        stats = {\n",
    "            '변수명': col,\n",
    "            '평균': col_data.mean(),\n",
    "            '표준편차': col_data.std(),\n",
    "            '최솟값': col_data.min(),\n",
    "            '최댓값': col_data.max(),\n",
    "            '왜도': col_data.skew(),\n",
    "            '첨도': col_data.kurtosis(),\n",
    "        }\n",
    "        # 이상값 비율\n",
    "        Q1 = col_data.quantile(0.25)\n",
    "        Q3 = col_data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        mask = (col_data < Q1 - 1.5 * IQR) | (col_data > Q3 + 1.5 * IQR)\n",
    "        outliers = col_data[mask]\n",
    "        stats['이상값비율(%)'] = (len(outliers) / len(col_data)) * 100\n",
    "\n",
    "        # 유일값 비율\n",
    "        stats['유일값비율(%)'] = (col_data.nunique() / len(col_data)) * 100\n",
    "        quality_report.append(stats)\n",
    "    quality_df = pd.DataFrame(quality_report).round(3)\n",
    "    display(quality_df)\n",
    "\n",
    "    # 4. 분포 이상 감지\n",
    "    print(f'\\n4. 분포 이상 감지')\n",
    "    print(f'\\n- 극심한 왜도(|skewness| > 2)')\n",
    "    high_skews = quality_df[abs(quality_df['왜도']) > 2]['변수명'].to_list()\n",
    "\n",
    "    if high_skews: # high_skews 리스트가 빈 리스트가 아니라면\n",
    "        for var in high_skews:\n",
    "            skew_val = quality_df[quality_df['변수명'] == var].iloc[0]['왜도']\n",
    "            print(f'--{var}: 왜도 = {skew_val: 3f}')\n",
    "    else:\n",
    "        print('-- 정상 범위 내 분포')\n",
    "\n",
    "    print('\\n- 높은 이상값 비율(>5%)')\n",
    "    high_outliers = quality_df[quality_df['이상값비율(%)'] > 5]['변수명'].tolist()\n",
    "    \n",
    "    print(high_outliers)\n",
    "    if high_outliers: # high_skews 리스트가 빈 리스트가 아니라면\n",
    "        for var in high_outliers:\n",
    "            outliers_pct = quality_df[quality_df['변수명'] == var].iloc[0]['이상값비율(%)']\n",
    "            print(f'--{var}: 이상값 = {outliers_pct:.1f}%')\n",
    "    else:\n",
    "        print('-- 이상값 비율 양호')\n",
    "\n",
    "    return quality_df\n",
    "\n",
    "\n",
    "get_data_profile(boston)\n",
    "print('dkdk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3c7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3단계: 시각적 품질 진단\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# 주요 변수들의 분포 시각화\n",
    "key_vars = ['PRICE', 'CRIM', 'RM', 'LSTAT', 'NOX', 'AGE', 'DIS', 'TAX', 'PTRATIO']\n",
    "\n",
    "for i, var in enumerate(key_vars):\n",
    "    if i < len(axes):\n",
    "        # 히스토그램과 박스플롯 조합\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # 히스토그램\n",
    "        ax.hist(boston[var], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        ax.set_title(f'{var} 분포\\n(평균: {boston[var].mean():.2f}, 왜도: {boston[var].skew():.2f})')\n",
    "        ax.set_xlabel(var)\n",
    "        ax.set_ylabel('빈도')\n",
    "        \n",
    "        # 평균선 표시\n",
    "        ax.axvline(boston[var].mean(), color='red', linestyle='--', alpha=0.8, label='평균')\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 상관관계 히트맵으로 품질 검증\n",
    "plt.figure(figsize=(14, 10))\n",
    "correlation_matrix = boston.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', \n",
    "            center=0, cmap='RdBu_r', square=True, cbar_kws={'label': '상관계수'})\n",
    "plt.title('Boston Housing 변수 간 상관관계')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== 상관관계 분석 결과 ===\")\n",
    "price_corr = correlation_matrix['PRICE'].abs().sort_values(ascending=False)\n",
    "print(\"PRICE와 상관관계가 높은 변수들:\")\n",
    "for var, corr in price_corr.items():\n",
    "    if var != 'PRICE' and corr > 0.5:\n",
    "        print(f\"  {var}: {corr:.3f} ({'양의 상관관계' if correlation_matrix['PRICE'][var] > 0 else '음의 상관관계'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245be258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5단계: 변수 간 논리적 일관성 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a3ebbd",
   "metadata": {},
   "source": [
    "## 결측치/이상치 탐지 및 처리(심화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 설치\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "plt.rcParams['font.family'] = 'GmarketSans'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0ecdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 온라인 소매 데이터 생성 (컬럼명 소문자 버전)\n",
    "np.random.seed(42)\n",
    "n_customers = 1000\n",
    "\n",
    "def create_realistic_ecommerce_data(n=1000):\n",
    "    \"\"\"실제와 유사한 전자상거래 데이터 생성 (소문자 컬럼명)\"\"\"\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    # 고객 기본 정보\n",
    "    data['customer_id'] = range(1, n+1)\n",
    "    data['age'] = np.random.normal(35, 12, n).clip(18, 80).astype(int)\n",
    "    data['gender'] = np.random.choice(['M', 'F'], n, p=[0.45, 0.55])\n",
    "    data['city'] = np.random.choice(['Seoul', 'Busan', 'Daegu', 'Incheon', 'Gwangju'], \n",
    "                                   n, p=[0.4, 0.2, 0.15, 0.15, 0.1])\n",
    "    \n",
    "    # 구매 행동 데이터\n",
    "    data['total_purchases'] = np.random.poisson(8, n) + 1\n",
    "    data['avg_order_value'] = np.random.lognormal(4.5, 0.8, n).round(2)\n",
    "    data['days_since_last_purchase'] = np.random.exponential(30, n).astype(int)\n",
    "    \n",
    "    # 만족도 및 충성도\n",
    "    data['satisfaction_score'] = np.random.normal(3.8, 1.2, n).clip(1, 5).round(1)\n",
    "    data['loyalty_points'] = (data['total_purchases'] * data['avg_order_value'] * 0.1 + \n",
    "                             np.random.normal(0, 100, n)).clip(0, None).round(0)\n",
    "    \n",
    "    # 카테고리별 구매 금액\n",
    "    categories = ['electronics', 'clothing', 'books', 'home', 'sports']\n",
    "    for cat in categories:\n",
    "        # 일부 고객은 특정 카테고리에서 구매하지 않음\n",
    "        values = np.random.lognormal(3, 1, n)\n",
    "        # 30% 확률로 해당 카테고리 구매 안 함 (0으로 설정)\n",
    "        mask = np.random.random(n) < 0.3\n",
    "        values[mask] = 0\n",
    "        data[f'{cat}_spending'] = values.round(2)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # 의도적 결측값 생성 (실제 상황 모방)\n",
    "    \n",
    "    # 1. MCAR: 완전 무작위 결측 (시스템 오류)\n",
    "    missing_indices = np.random.choice(df.index, size=int(0.05 * len(df)), replace=False)\n",
    "    df.loc[missing_indices, 'satisfaction_score'] = np.nan\n",
    "    \n",
    "    # 2. MAR: 조건부 결측 (나이가 높을수록 만족도 응답 거부율 증가)\n",
    "    elderly_mask = df['age'] > 50\n",
    "    elderly_missing = np.random.random(elderly_mask.sum()) < 0.15  \n",
    "    elderly_indices = df[elderly_mask].index[elderly_missing]\n",
    "    df.loc[elderly_indices, 'satisfaction_score'] = np.nan\n",
    "    \n",
    "    # 3. MNAR: 결측 자체가 의미 (높은 소득자들이 개인정보 비공개)\n",
    "    high_spenders = df['avg_order_value'] > df['avg_order_value'].quantile(0.8)\n",
    "    high_spender_missing = np.random.random(high_spenders.sum()) < 0.25\n",
    "    high_spender_indices = df[high_spenders].index[high_spender_missing]\n",
    "    df.loc[high_spender_indices, 'age'] = np.nan\n",
    "    \n",
    "    # 도시 정보 일부 결측 (배송지 미입력)\n",
    "    city_missing = np.random.choice(df.index, size=int(0.08 * len(df)), replace=False)\n",
    "    df.loc[city_missing, 'city'] = np.nan\n",
    "    \n",
    "    # 의도적 이상값 생성\n",
    "    \n",
    "    # 1. 데이터 입력 오류 (나이 999살)\n",
    "    error_indices = np.random.choice(df.index, size=3, replace=False)\n",
    "    df.loc[error_indices, 'age'] = 999\n",
    "    \n",
    "    # 2. 비즈니스 이상값 (VIP 고객의 극도로 높은 구매액)  Extreme but Valid Outliers\n",
    "    vip_indices = np.random.choice(df.index, size=5, replace=False)\n",
    "    df.loc[vip_indices, 'avg_order_value'] *= 20\n",
    "    df.loc[vip_indices, 'loyalty_points'] *= 10\n",
    "    \n",
    "    # 3. 시스템 버그로 인한 음수값\n",
    "    bug_indices = np.random.choice(df.index, size=2, replace=False) \n",
    "    df.loc[bug_indices, 'days_since_last_purchase'] = -1\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 데이터 생성\n",
    "ecommerce = create_realistic_ecommerce_data(1000)\n",
    "\n",
    "print(\"=== 온라인 소매 데이터 개요 ===\")\n",
    "print(f\"데이터 크기: {ecommerce.shape}\")\n",
    "print(\"\\n데이터 샘플:\")\n",
    "display(ecommerce.head(10))\n",
    "\n",
    "print(f\"\\n기본 정보:\")\n",
    "print(ecommerce.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc53e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전에 만든 profile 함수를 써서 결측치 전반적으로 확인.\n",
    "\n",
    "from da_utils.profile import get_data_profile   # 이거는 폴더 내 파일의 함수만 꺼낸 것.\n",
    "# from da_utils import profile                    # 얘는 폴더 내 파일 전체를 꺼낸 것.\n",
    "# 참고로 2번 방식으로 부르게 되면 profile.get_data_profile() 이라는 식으로 써야 함.\n",
    "data_report = get_data_profile(ecommerce)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114eb5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "plt.rcParams['font.family'] = 'GmarketSans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def analyze_missing_patterns(df: pd.DataFrame):\n",
    "    \"\"\"결측값 패턴 종합 분석\"\"\"\n",
    "    print('=== 결측값 패턴 분석 ===')\n",
    "    missing_info = df.isna().sum()\n",
    "    missing_pct = (missing_info / len(df)) * 100\n",
    "    missing_summary = pd.DataFrame({\n",
    "        '결측수': missing_info,\n",
    "        '결측률(%)': missing_pct.round(2)\n",
    "    })\n",
    "    missing_summary = missing_summary[missing_summary['결측수'] > 0].sort_values('결측수', ascending=False)\n",
    "    print('변수별 결측 현황')\n",
    "    display(missing_summary)\n",
    "\n",
    "    # 결측값 시각화\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    a1, a2, a3, a4 = axes[0, 0], axes[0, 1], axes[1, 0], axes[1, 1]\n",
    "    \n",
    "    # 1. 결측값 히트맵\n",
    "    sns.heatmap(df.isna(), yticklabels=False, cbar=True, cmap='viridis', ax=a1)\n",
    "    a1.set_title('결측값 패턴 히트맵')\n",
    "    # a1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "    # 2. 별수별 결측률 바 파트\n",
    "    if len(missing_summary):\n",
    "        missing_summary['결측률(%)'].plot(kind='bar', color='coral', ax=a2)\n",
    "        a2.set_title('변수별 결측률')\n",
    "        a2.set_ylabel('결측률(%)')\n",
    "        a2.tick_params(axis='x', rotation=0)\n",
    "\n",
    "    # 3. 결측값 조합 패턴\n",
    "    # 결측값이 있는 컬럼들만 T/F 표시\n",
    "    missing_pattern = df[df.columns[df.isna().any()]].isna()     # colums 중 결측값이 있는 컬럼들의 데이터 프레임을 재구성하겠다는 뜻.\n",
    "    if len(missing_pattern):\n",
    "        # 결측 패턴 조합 상위 10개(갯수 기준)\n",
    "        pattern_counts = missing_pattern.value_counts().head(10)\n",
    "        pattern_counts.plot(kind='bar', color='lightblue', ax=a3)\n",
    "        a3.set_title('결측 패턴 조합(상위 10)')\n",
    "        a3.set_ylabel('빈도')\n",
    "        a3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "     # 4. 결측 변수별 결측 여부(0/1)와 다른 수치형 변수 간 상관관계 히트맵 시각화\n",
    "    numeric_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "    missing_cols = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "    if len(numeric_cols) > 0 and len(missing_cols) > 0:\n",
    "        # 결측값을 0/1로 변환한 DataFrame 생성\n",
    "        missing_binary = df[missing_cols].isna().astype(int)\n",
    "        missing_binary.columns = [f'{col}_missing' for col in missing_binary.columns]\n",
    "        \n",
    "        # 수치형 변수와 결측 패턴 변수 결합\n",
    "        corr_data = pd.concat([df[numeric_cols], missing_binary], axis=1)\n",
    "        \n",
    "        # 상관계수 계산\n",
    "        correlation_matrix = corr_data.corr()\n",
    "        \n",
    "        # 결측 패턴 변수와 수치형 변수 간의 상관관계만 추출\n",
    "        missing_numeric_corr = correlation_matrix.loc[\n",
    "            missing_binary.columns, \n",
    "            numeric_cols\n",
    "        ]\n",
    "        \n",
    "        # 상관관계가 있는 경우에만 히트맵 그리기\n",
    "        if missing_numeric_corr.shape[0] > 0 and missing_numeric_corr.shape[1] > 0:\n",
    "            sns.heatmap(missing_numeric_corr, \n",
    "                    annot=True, \n",
    "                    cmap='coolwarm', \n",
    "                    center=0,\n",
    "                    fmt='.2f',\n",
    "                    ax=a4,\n",
    "                    cbar_kws={'label': '상관계수'})\n",
    "            a4.set_title('결측 패턴과 수치형 변수 간 상관관계')\n",
    "            a4.set_xlabel('수치형 변수')\n",
    "            a4.set_ylabel('결측 패턴')\n",
    "        else:\n",
    "            a4.text(0.5, 0.5, '분석할 상관관계 없음', ha='center', va='center')\n",
    "            a4.axis('off')\n",
    "    else:\n",
    "        a4.text(0.5, 0.5, '수치형 변수 또는\\n결측값이 없음', ha='center', va='center')\n",
    "        a4.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return missing_summary\n",
    "\n",
    "\n",
    "\n",
    "analyze_missing_patterns(ecommerce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# 결측 매커니즘 진단.\n",
    "\n",
    "print('=== 결측 메커니즘 진단 ===')\n",
    "\n",
    "# MAR 패턴 Missing At Random -> (조건부) 무작위 결측\n",
    "# MAR 패턴 검증: 나이 결측과 구매액의 관계\n",
    "\n",
    "if ecommerce['age'].isnull().sum() > 0: # age에 결측값이 있는지?\n",
    "    print('나이(age) 결측 메커니즘 분석')\n",
    "\n",
    "    # 구매액 분위별 나이 결측률 check\n",
    "    df_temp = ecommerce.copy()\n",
    "    df_temp['spending_quartile'] = pd.qcut(df_temp['avg_order_value'].dropna(), q=4, labels=['하위25', '상위75', '상위50', '상위25'])\n",
    "    age_missing_my_spending = df_temp.groupby('spending_quartile')['age'].apply(lambda x: x.isnull().mean()) # age가 비어있는 컬럼의 비율을 보겠다는 뜻.\n",
    "    # isnull()로 바꾸면, 조건에 맞는 값은 1로 바뀜.\n",
    "    # 고로 전체의 평균값을 내면 전체 중 조건에 맞는 비율이 보임.\n",
    "\n",
    "    print('\\n구매액 분위별 나이 결측률')\n",
    "    for key, value in age_missing_my_spending.items():  # items: 딕셔너리 키+밸류를 튜플값으로 반환.\n",
    "        print(f'{key}: {value:.1%}')\n",
    "\n",
    "\n",
    "    con_table = pd.crosstab(df_temp['spending_quartile'], df_temp['age'].isnull())  # crosstab이 머임.\n",
    "\n",
    "    chi2, pvalue, _, _ = chi2_contingency(con_table)   # 올ㅋ\n",
    "    pvalue  \n",
    "\n",
    "    print(f'\\n카이제곱 통계량: {chi2: .3f}, pvalue: {pvalue: .4f}')\n",
    "    if pvalue < 0.05:\n",
    "        print('✅ MAR 패턴 확인: 구매액에 따라 나이 결측률이 유의미하게 다름')\n",
    "    else:\n",
    "        print('❌ MCAR 가능성 있음: 구매액과 나이 결측이 독립적')\n",
    "else:\n",
    "    print('age 결측 없음')\n",
    "\n",
    "# 만족도 결측 패턴 분석\n",
    "print('\\n 만족도(Satisfaction_score) 결측 메커니즘 분석')\n",
    "\n",
    "# 연령대별 만족도 결측률(0, 30, 50, 100) - ['청년층', '중년층', '장년층']\n",
    "# 각구간마다 만족도가 없는 사람들의 %를 구하기.\n",
    "\n",
    "# 연령대별 나이 결측률 check\n",
    "df_temp = ecommerce.copy()\n",
    "df_temp['age_quartile'] = pd.cut(df_temp['age'].dropna(), bins=[0, 30, 50, 100], labels=['청년', '중년', '장년'])\n",
    "satisf_missing_by_age = df_temp.groupby('age_quartile')['satisfaction_score'].apply(lambda x: x.isnull().mean()) # stisf_score가 비어있는 컬럼의 비율을 보겠다는 뜻.\n",
    "# isnull()로 바꾸면, 조건에 맞는 값은 1로 바뀜.\n",
    "# 고로 전체의 평균값을 내면 전체 중 조건에 맞는 비율이 보임.\n",
    "\n",
    "print('\\n연령대별 만족도 결측률')\n",
    "for key, value in satisf_missing_by_age.items():  # items: 딕셔너리 키+밸류를 튜플값으로 반환.\n",
    "    print(f'{key}: {value:.1%}')\n",
    "\n",
    "\n",
    "con_table = pd.crosstab(df_temp['age_quartile'], df_temp['satisfaction_score'].isnull())  \n",
    "\n",
    "# 성별 나이 결측률 check\n",
    "satisf_missing_by_gender = df_temp.groupby('gender')['satisfaction_score'].apply(lambda x: x.isnull().mean()) # stisf_score가 비어있는 컬럼의 비율을 보겠다는 뜻.\n",
    "# isnull()로 바꾸면, 조건에 맞는 값은 1로 바뀜.\n",
    "# 고로 전체의 평균값을 내면 전체 중 조건에 맞는 비율이 보임.\n",
    "\n",
    "print('\\n성별 만족도 결측률')\n",
    "for key, value in satisf_missing_by_gender.items():  # items: 딕셔너리 키+밸류를 튜플값으로 반환.\n",
    "    print(f'{key}: {value:.1%}')\n",
    "\n",
    "\n",
    "con_table = pd.crosstab(df_temp['gender'], df_temp['satisfaction_score'].isnull())  \n",
    "\n",
    "plt.subplots(1, 3, figsize=(15, 10))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = ecommerce.copy()\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99429db7",
   "metadata": {},
   "source": [
    "## 고급 결측값 대체 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e0a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a75c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute -> 대체하다.\n",
    "from pkg_resources import find_eggs_in_zip\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# 숫자형 컬럼들\n",
    "numeric_cols = ['age', 'total_purchases', 'avg_order_value',\n",
    "       'days_since_last_purchase', 'satisfaction_score', 'loyalty_points']\n",
    "# ecommerce.select_dtypes(include='number').columns\n",
    "df_numeric = ecommerce[numeric_cols]\n",
    "print('원본 데이터 결측률')\n",
    "for col in numeric_cols:\n",
    "    missing_rate = df_numeric[col].isnull().mean()\n",
    "    if missing_rate:\n",
    "        print(f' {col}: {missing_rate: .2%}')\n",
    "\n",
    "# 1. 컬럼별 결측치 평균값으로 대체\n",
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "df_mean = df_numeric.copy()\n",
    "df_mean[numeric_cols] = imputer_mean.fit_transform(df_numeric[numeric_cols])    # 이렇게 하면 평균으로 알아서 채워줌\n",
    "\n",
    "#(여기부터 고오오오오급)\n",
    "# 2. KNN 대체\n",
    "# K-Nearest Neighbors: \n",
    "imputer_knn = KNNImputer(n_neighbors=5)\n",
    "df_knn = df_numeric.copy()\n",
    "df_knn[numeric_cols] = imputer_knn.fit_transform(df_numeric[numeric_cols])  \n",
    "\n",
    "# 2. mice 대체\n",
    "# Multiple Imputation by Chained Equations: 결측이 있는 변수를 다른 변수를 이용해 `회귀`모델 예측\n",
    "# 변수간 상관관계가 약한경우, 평균으로 도달.\n",
    "imputer_mice = IterativeImputer(random_state=42, max_iter=10)\n",
    "df_mice = df_numeric.copy()\n",
    "df_mice[numeric_cols] = imputer_mice.fit_transform(df_numeric[numeric_cols]) \n",
    "\n",
    "# display(df_mean)\n",
    "# display(df_knn)\n",
    "# display(df_mice)\n",
    "\n",
    "# 대체 결과 비교 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "a1, a2, a3, a4 = axes[0, 0], axes[0, 1], axes[1, 0], axes[1, 1]\n",
    "\n",
    "# age 변수 대체 결과\n",
    "variable = 'age'\n",
    "if df_numeric[variable].isnull().sum():\n",
    "    x_min, x_max = 0, 100\n",
    "    sns.histplot(df_numeric[variable], binwidth=2, kde=False, ax=a1, alpha=0.3, label='원본', color='lightblue')\n",
    "    sns.histplot(df_mean[variable], binwidth=2, kde=False, ax=a1, alpha=0.3, label='원본', color='coral')\n",
    "    \n",
    "    a1.set_xlim(x_min, x_max)\n",
    "\n",
    "    sns.histplot(df_numeric[variable], binwidth=2, kde=False, ax=a2, alpha=0.3, label='원본', color='lightblue')\n",
    "    sns.histplot(df_knn[variable], binwidth=2, kde=False, ax=a2, alpha=0.3, label='원본', color='green')\n",
    "    a2.set_xlim(x_min, x_max)\n",
    "\n",
    "    sns.histplot(df_numeric[variable], binwidth=2, kde=False, ax=a3, alpha=0.3, label='원본', color='lightblue')\n",
    "    sns.histplot(df_mice[variable], binwidth=2, kde=False, ax=a3, alpha=0.3, label='원본', color='yellow')\n",
    "    a3.set_xlim(x_min, x_max)\n",
    "\n",
    "# 대체 전후 통계량 비교\n",
    "comparison_stats = pd.DataFrame({\n",
    "    '원본': df_numeric[variable].describe(),\n",
    "    '평균대체': df_mean[variable].describe(),\n",
    "    'KNN': df_knn[variable].describe(),\n",
    "    'mice': df_mice[variable].describe()\n",
    "}).round(2)\n",
    "\n",
    "# 텍스트로 통계 비교 표시\n",
    "a4.axis('off')\n",
    "a4.table(\n",
    "    cellText=comparison_stats.values,\n",
    "    rowLabels=comparison_stats.index,\n",
    "    colLabels=comparison_stats.columns,\n",
    "    cellLoc='center',\n",
    "    loc='center'\n",
    ")\n",
    "a4.set_title(f'{variable} 대체 방법별 통계량 비교')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7603c",
   "metadata": {},
   "source": [
    "## 대체 품질 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== 대체 품질 평가 ===')\n",
    "evaluation_results = []\n",
    "\n",
    "original_df = df_numeric\n",
    "imputed_dfs = df_mean, df_knn, df_mice\n",
    "method_names = ['평균대체', 'KNN대체', 'MICE대체']\n",
    "\n",
    "# 위 1행과 2행을 튜플로 묶음.(싱기방기))\n",
    "list(zip(method_names, imputed_dfs))\n",
    "\n",
    "for method, imputed_df in zip(method_names, imputed_dfs):\n",
    "    for col in ['age', 'satisfaction_score']:\n",
    "        if original_df[col].isnull().sum():\n",
    "            original_stats = original_df[col].dropna().describe()\n",
    "            imputed_stats = imputed_df[col].describe()\n",
    "            # 평균 차이(%)\n",
    "            mean_diff = abs(original_stats['mean'] - imputed_stats['mean']) / original_stats['mean'] * 100\n",
    "            # 표준편(%)) 차이\n",
    "            std_diff = abs(original_stats['std'] - imputed_stats['std']) / original_stats['std'] * 100\n",
    "            evaluation_results.append({\n",
    "                '방법': method,\n",
    "                '변수': col,\n",
    "                '평균차이(%)': mean_diff,\n",
    "                '표준편차차이(%)': std_diff\n",
    "            })\n",
    "    \n",
    "    \n",
    "        # 2. 상관관계 보존 평가\n",
    "        # age <-> avg_order_value(지금은 임의 선정, 원래는 검증을 통해서 상관관계가 있는지 봐야함)\n",
    "        original_corr = original_df[['age', 'avg_order_value']].corr().iloc[0, 1]  # 얘는 결측치 포함\n",
    "        # original_comp_corr = original_df[['age', 'avg_order_value']].dropna().corr().iloc[0, 1]  # 얘는 결측치 삭제\n",
    "        imputed_corr = imputed_df[['age', 'avg_order_value']].dropna().corr().iloc[0, 1]    # 얘는 결측치 메움(3가지 방식으로)\n",
    "        \n",
    "        # 상관관계 유지 정도\n",
    "        # corr_preservation = abs(original_comp_corr - imputed_corr) / abs(original_comp_corr) * 100 # 역사속으로 사라지세요.\n",
    "        og_corr_preservation = abs(original_corr - imputed_corr) / abs(original_corr) * 100\n",
    "\n",
    "        evaluation_results.append({\n",
    "            '방법': method,\n",
    "            '변수': 'Age-구매액 상관관계',\n",
    "            '원본상관계수': original_corr,\n",
    "            # '삭제상관계수': original_comp_corr,\n",
    "            '대체상관계수': imputed_corr,\n",
    "            '상관계수보존도(%)': 100 - og_corr_preservation,\n",
    "    })\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "eval_df = pd.DataFrame(evaluation_results)\n",
    "\n",
    "\n",
    "print('1. 분포 보존 성능')\n",
    "dist_eval = eval_df[eval_df['변수'].isin(('age', 'satisfaction_score'))]\n",
    "print(dist_eval[[\n",
    "    '방법',\t'변수',\t'평균차이(%)',\t'표준편차차이(%)'\n",
    "]].to_string(index=False))\n",
    "\n",
    "print('\\n2. 상관관계 보존성능')\n",
    "corr_eval = eval_df[eval_df['변수'].isin(('Age-구매액 상관관계', 'satisfaction_score-구매액 상관관계'))]\n",
    "for _, row in corr_eval.iterrows():\n",
    "    print(f'{row['방법']}: 보존도 {row['상관계수보존도(%)']:.1f}%')\n",
    "    print(f'(원본: {row['원본상관계수']:.3f} -> 대체후: {row['대체상관계수']:.3f})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13250c21",
   "metadata": {},
   "source": [
    "## 이상값 탐지 및 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a08a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 설치\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "plt.rcParams['font.family'] = 'GmarketSans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "\n",
    "# it was IQR, 3∂\n",
    "# 이상치를 범용적으로 탐지하는 건 꽤 어려운 작업임(그나마가 IQR)\n",
    "def outlier_detection(df: pd.DataFrame, chi_q=0.999, iso_cont=0.1, final_threshold=2):\n",
    "    print('=== 종합 이상값 탐지 시스템 ===')\n",
    "    df_copy = df.copy()\n",
    "    numeric_data = df_copy.select_dtypes(include=['number']) # 우리는 수치형 데이터만 확인할 거기 때문에.\n",
    "\n",
    "\n",
    "    # 1. IQR 이상값\n",
    "    print('1. 일변량 이상값 탐지 (IQR 방법)')   # 변수 하나만 보고 이상한지 아닌지 판단하겠다.(키 250)\n",
    "    # 다변량: 종합적으로 보면 이상해(키 190 몸무게 45)\n",
    "    univariate_outliers = pd.DataFrame(index=df_copy.index)\n",
    "    \n",
    "    for col in numeric_data.columns:\n",
    "        Q1 = df_copy[col].quantile(0.25)\n",
    "        Q3 = df_copy[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers_mask = (df_copy[col] < lower_bound ) | (df_copy[col] > upper_bound)\n",
    "        univariate_outliers[col] = outliers_mask\n",
    "\n",
    "        # display(univariate_outliers)    # 이 때 나타나는 True는 한 줄의 col 내에서 이상한 값들.\n",
    "        outlier_count = outliers_mask.sum()\n",
    "        if outlier_count:\n",
    "            print(f'  {col}: {outlier_count}개 ({outlier_count / len(df_copy) * 100:.1f}%)')\n",
    "    \n",
    "    # 2. 마할라노비스 거리 기반 다변량 이상값\n",
    "    # => 데이터가 정규분포를 따를 때, 유용함.\n",
    "    print('\\n2. 다변량 이상값 탐지 (마할라노비스 거리)')\n",
    "    scaler = StandardScaler() # 인스턴스 만들기\n",
    "    \n",
    "    # 평균 0, 표준편차 1로 조정된 데이터\n",
    "    scaled_df = pd.DataFrame(\n",
    "        scaler.fit_transform(numeric_data),\n",
    "        columns=numeric_data.columns,\n",
    "        index=numeric_data.index\n",
    "    )\n",
    "    # 데이터 평균 벡터\n",
    "    mean = scaled_df.mean().values\n",
    "    # 공분산 행렬\n",
    "    cov_matrix = np.cov(scaled_df, rowvar=False)\n",
    "    # 공분산 행렬의 역행렬\n",
    "    inv_cov_matrix = np.linalg.pinv(cov_matrix)\n",
    "    # 마할라노비스 거리 계산\n",
    "    mahal_distance = scaled_df.apply(lambda row: distance.mahalanobis(row, mean, inv_cov_matrix), axis=1)\n",
    "    \n",
    "\n",
    "    # 이상치 기준점(임계점, threshold) 지정 (카이제곱 분포 기준 ->  0.95, 0.99, 0.999)\n",
    "    threshold = chi2.ppf(chi_q, len(numeric_data.columns)) ** 0.5\n",
    "    mahal_outliers = mahal_distance > threshold\n",
    "    print(f' 임계값(거리): {threshold:.2f}')\n",
    "    print(f' 다변량 이상값: {mahal_outliers.sum()}개 ({mahal_outliers.mean() * 100:.1f}%)')\n",
    "\n",
    "    # 3. IsolationForest기반 다변량 이상값\n",
    "    # 데이터가 정상인지 비정상인지를 나눔.\n",
    "    # 얘는 마할라노비스랑 다르게, 데이터 이상치가 너무 복잡할 때 사용.\n",
    "    print('\\n3. 다변량 이상값 탐지(Isolation Forest)')\n",
    "    iso_forest = IsolationForest(contamination=iso_cont, random_state = 42)\n",
    "    isolation_outliers = iso_forest.fit_predict(scaled_df) == -1\n",
    "    isolation_scores = iso_forest.score_samples(scaled_df)\n",
    "    print(f'  Isolation Forest 이상값: {isolation_outliers.sum()}개 ({isolation_outliers.mean() * 100:.1f}%)')\n",
    "\n",
    "    # 4. 비즈니스 규칙(특화) 이상값 # 얘는 범용성이 없음\n",
    "    print('\\n4. 비즈니스 규칙 기반 이상값:')\n",
    "    business_outliers = (\n",
    "        (df['age']  > 130) |\n",
    "        (df['days_since_last_purchase']  < 0) |\n",
    "        (df['avg_order_value'] > 10000000)\n",
    "    )\n",
    "    print(f'  비즈니스 규칙 이상값: {business_outliers.sum()}개 ({business_outliers.mean() * 100:.3f}%)')\n",
    "\n",
    "\n",
    "    # 5. 종합판정\n",
    "    outlier_summary = pd.DataFrame({\n",
    "        '일변량': univariate_outliers.sum(axis=1) > 0,\n",
    "        'Mahal Dist': mahal_outliers,\n",
    "        'Iso Forest': isolation_outliers,\n",
    "        'Business': business_outliers,\n",
    "    })\n",
    "    outlier_summary['총이상값수'] = outlier_summary.sum(axis=1)\n",
    "    final_outliers = outlier_summary['총이상값수'] >= final_threshold\n",
    "    print(f'\\n == 최종 이상값: {final_outliers.sum()}개 ({final_outliers.mean() * 100:.1f}%)')\n",
    "    \n",
    "    return outlier_summary, final_outliers\n",
    "summary, final_outliers = outlier_detection(df_knn, chi_q=0.999, iso_cont=0.1, final_threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_interpretation_strategy(df, outliers_mask):\n",
    "    \"\"\"이상값 해석 및 처리 전략 수립\"\"\"\n",
    "    \n",
    "    print(\"=== 이상값 해석 및 처리 전략 ===\")\n",
    "    \n",
    "    # 이상값 특성 분석\n",
    "    normal_customers = df[~outliers_mask]\n",
    "    outlier_customers = df[outliers_mask]\n",
    "    \n",
    "    if len(outlier_customers) == 0:\n",
    "        print(\"이상값이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    print(\"1. 이상값 vs 정상값 비교 분석:\")\n",
    "    \n",
    "    comparison_vars = ['age', 'total_purchases', 'avg_order_value', 'days_since_last_purchase', 'loyalty_points']\n",
    "    \n",
    "    comparison_stats = pd.DataFrame({\n",
    "        '정상고객_평균': normal_customers[comparison_vars].mean(),\n",
    "        '이상값고객_평균': outlier_customers[comparison_vars].mean(),\n",
    "        '정상고객_중위수': normal_customers[comparison_vars].median(),\n",
    "        '이상값고객_중위수': outlier_customers[comparison_vars].median()\n",
    "    }).round(2)\n",
    "    \n",
    "    comparison_stats['차이배수'] = (comparison_stats['이상값고객_평균'] / comparison_stats['정상고객_평균']).round(2)\n",
    "    \n",
    "    print(comparison_stats)\n",
    "    \n",
    "    # 2. 이상값 분류 및 처리 전략\n",
    "    print(f\"\\n2. 이상값 분류 및 처리 전략:\")\n",
    "    \n",
    "    # VIP 고객 (높은 구매액 + 높은 충성도)\n",
    "    vip_mask = (outlier_customers['avg_order_value'] > normal_customers['avg_order_value'].quantile(0.95)) & \\\n",
    "               (outlier_customers['loyalty_points'] > normal_customers['loyalty_points'].quantile(0.95))\n",
    "    vip_count = vip_mask.sum()\n",
    "    \n",
    "    # 데이터 오류 (나이 999살, 음수 날짜 등)\n",
    "    error_mask = (outlier_customers['age'] > 100) | (outlier_customers['days_since_last_purchase'] < 0)\n",
    "    error_count = error_mask.sum()\n",
    "    \n",
    "    # 이상 행동 고객 (오랫동안 구매 없음)\n",
    "    dormant_mask = outlier_customers['days_since_last_purchase'] > normal_customers['days_since_last_purchase'].quantile(0.95)\n",
    "    dormant_count = dormant_mask.sum()\n",
    "    \n",
    "    print(f\"이상값 분류:\")\n",
    "    print(f\"  VIP 고객 (특별 관리 대상): {vip_count}명\")\n",
    "    print(f\"  데이터 오류 (수정/제거 필요): {error_count}명\") \n",
    "    print(f\"  휴면 고객 (재활성화 대상): {dormant_count}명\")\n",
    "    print(f\"  기타 이상값: {len(outlier_customers) - vip_count - error_count - dormant_count}명\")\n",
    "    \n",
    "    # 시각화 (소문자 변수명 사용)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    a1, a2, a3, a4 = axes[0, 0], axes[0, 1], axes[1, 0], axes[1, 1]\n",
    "    # 구매액 분포 비교\n",
    "    a1.hist(normal_customers['avg_order_value'], bins=30, alpha=0.7, label='정상고객', color='blue')\n",
    "    a1.hist(outlier_customers['avg_order_value'], bins=30, alpha=0.7, label='이상값고객', color='red')\n",
    "    a1.set_title('평균 구매액 분포 비교')\n",
    "    a1.set_xlabel('평균 구매액')\n",
    "    a1.legend()\n",
    "    \n",
    "    # 나이 분포 비교\n",
    "    a2.hist(normal_customers['age'], bins=30, alpha=0.7, label='정상고객', color='blue')\n",
    "    a2.hist(outlier_customers['age'], bins=30, alpha=0.7, label='이상값고객', color='red')\n",
    "    a2.set_title('나이 분포 비교')\n",
    "    a2.set_xlabel('나이')\n",
    "    a2.legend()\n",
    "    \n",
    "    # 구매액 vs 충성도 포인트 산점도\n",
    "    a3.scatter(normal_customers['avg_order_value'], normal_customers['loyalty_points'], \n",
    "                     alpha=0.6, label='정상고객', color='blue', s=20)\n",
    "    a3.scatter(outlier_customers['avg_order_value'], outlier_customers['loyalty_points'], \n",
    "                     alpha=0.8, label='이상값고객', color='red', s=50)\n",
    "    a3.set_xlabel('평균 구매액')\n",
    "    a3.set_ylabel('충성도 포인트')\n",
    "    a3.set_title('구매액 vs 충성도 포인트')\n",
    "    a3.legend()\n",
    "    \n",
    "    # 마지막 구매 후 경과일 분포\n",
    "    a4.hist(normal_customers['days_since_last_purchase'], bins=30, alpha=0.7, label='정상고객', color='blue')\n",
    "    a4.hist(outlier_customers['days_since_last_purchase'], bins=30, alpha=0.7, label='이상값고객', color='red')\n",
    "    a4.set_title('마지막 구매 후 경과일 분포')\n",
    "    a4.set_xlabel('경과일')\n",
    "    a4.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 이상값 해석 및 전략 수립\n",
    "outlier_strategies = outlier_interpretation_strategy(df_mice, final_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed99ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상값 처리 실행\n",
    "def execute_outlier_treatment(df: pd.DataFrame, outliers_mask):\n",
    "    print('=== 이상값 처리 실행 ===')\n",
    "    df_treated = df.copy()\n",
    "    outliers = df[outliers_mask]\n",
    "    if len(outliers) == 0:\n",
    "        print('처리할 이상값 없음')\n",
    "        return df_treated\n",
    "    \n",
    "    print(f'처리 대상 이상값: {len(outliers)}개')\n",
    "    # 1. VIP 고객 처리(별도 세그먼트 분리)\n",
    "    vip_mask = (outliers['avg_order_value'] > df['avg_order_value'].quantile(0.95)) & \\\n",
    "               (outliers['loyalty_points'] > df['loyalty_points'].quantile(0.95))\n",
    "    \n",
    "    # VIP index 모음\n",
    "    vip_indices = outliers[vip_mask].index\n",
    "    # 행=VIP들만 뽑고, 해당 사람들만 컬럼-값 추가.\n",
    "    df_treated.loc[vip_indices, 'customer_segment'] = 'VIP'  # outlier 중에서 vip 고름.\n",
    "    print(f'  VIP 고객 분리: {len(vip_indices)}명')\n",
    "\n",
    "    # 2. 데이터 입력 오류 수정(e.g. age -> 999)\n",
    "    error_mask = (outliers['age'] > 120) | (outliers['days_since_last_purchase'] < 0) # 미리 이상치 체크해놓고 난 뒤에 확인\n",
    "    error_indices = outliers[error_mask].index\n",
    "\n",
    "    # 2-1. 나이 이상치 -> 결측치 윈저화? 최댓값? 평균값?\n",
    "    age_error_mask = outliers['age'] > 100\n",
    "    age_error_indices = outliers[age_error_mask].index\n",
    "    df_treated.loc[age_error_indices, 'age'] = np.nan                  # 이거 ㅅㅂ 무슨 말이야.\n",
    "    print(f'  나이 오류 -> 결측 처리: {age_error_mask.sum()}건')\n",
    "    \n",
    "    # 2-2. 음수 일수 -> 0으로 변경\n",
    "    negative_days_mask = outliers['days_since_last_purchase'] < 0\n",
    "    negative_days_indices = outliers[negative_days_mask].index\n",
    "    df_treated.loc[negative_days_indices, 'days_since_last_purchase'] = 0\n",
    "    print(f'  음수 일수 -> 0으로 대체: {negative_days_mask.sum()}건')\n",
    "\n",
    "    # 3. 극단적 구매액 처리(윈저화)\n",
    "    # 안 할 거면 하지마. ㅇㅇ\n",
    "    extreme_spending_mask = df_treated['avg_order_value'] > df_treated['avg_order_value'].quantile(0.99)\n",
    "    extreme_spending_indices = outliers[extreme_spending_mask].index\n",
    "    df_treated.loc[extreme_spending_indices, 'avg_order_value']\n",
    "    winsor_threshold = df_treated['avg_order_value'].quantile(0.99)\n",
    "    df_treated.loc[extreme_spending_indices, 'avg_order_value'] = winsor_threshold\n",
    "    print(f'  극단적 구매액 윈저화: {extreme_spending_mask.sum()}건 - ({winsor_threshold:.3f})딸라')\n",
    "\n",
    "    # 4. 휴면 고객 처리(별도 플래그 생성)\n",
    "    # 이상치의 기준으로 잡는 값\n",
    "    dormant_threshold = df_treated['days_since_last_purchase'].quantile(0.95)\n",
    "    # 기준 넘어가는 이상치에 대한 마스크 생성.\n",
    "    dormant_mask = outliers['days_since_last_purchase'] > df_treated['days_since_last_purchase'].quantile(0.95)\n",
    "    dormant_indices = outliers[dormant_mask].index\n",
    "    active_indices = df_treated[~dormant_mask].index\n",
    "    df_treated.loc[dormant_indices, 'customer_status'] = '휴면고객(이탈위험)'\n",
    "    df_treated.loc[active_indices, 'customer_status'] = '휴면고객 아님'\n",
    "    print(f'  휴면 고객 플래그 생성: {dormant_mask.sum()}명 {dormant_threshold:.3f}일 이상')\n",
    "    display(df_treated)\n",
    "    # 5. 처리 고객 요약.\n",
    "    print(f'\\n처리 결과 요약')\n",
    "    print(f'\\n  원본 데이터: {len(df)}건')\n",
    "    print(f'\\n  VIP 세그먼트: {(df_treated.get('customer_segment', '') == 'VIP').sum()}명')\n",
    "    print(f'\\n  휴면 고객: {(df_treated.get('customer_status', '') == '휴면고객').sum()}건')\n",
    "    print(f'\\n  활성 고객: {(df_treated.get('customer_status', '') == '활성고객').sum()}건')\n",
    "\n",
    "    # 6. 이상치 처리로 생긴 결측치 처리 (나이 오류 채우기)\n",
    "    # 다른 자료를 가지고 머신러닝 학습시켜서 나이 결측값 채우기\n",
    "    if df_treated['age'].isnull().sum() > 0:\n",
    "        print('\\n 추가 결측치 처리')\n",
    "        from sklearn.impute import KNNImputer\n",
    "        age_imputer = KNNImputer(n_neighbors=5)\n",
    "        #  비슷함을 참고할 컬럼들\n",
    "        cols = ['avg_order_value', 'days_since_last_purchase', 'loyalty_points']\n",
    "        impute_data = df_treated[['age'] + cols]\n",
    "        imputed = age_imputer.fit_transform(impute_data)\n",
    "        df_treated['age'] = imputed[:, 0]\n",
    "        print(f'  KNN으로 나이 결측값 대체: {age_error_mask.sum()}건')\n",
    "\n",
    "\n",
    "\n",
    "execute_outlier_treatment(df_knn, final_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920dec43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
